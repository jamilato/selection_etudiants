# ğŸš€ Quick Start - EntraÃ®nement du ModÃ¨le

## Guide ultra-rapide pour dÃ©marrer l'entraÃ®nement

---

## âš¡ En 5 Commandes

```bash
# 1. Activer environnement (depuis WSL Ubuntu)
cd /mnt/c/Users/MNB/Downloads/"Projet IA identification Ã©tudiant"
source venv_emotion/bin/activate

# 2. TÃ©lÃ©charger FER2013
python scripts/download_datasets.py --dataset fer2013

# 3. PrÃ©parer les donnÃ©es
python scripts/prepare_data.py --dataset data/fer2013 --all

# 4. Lancer l'entraÃ®nement
python scripts/train.py

# 5. Monitorer avec TensorBoard (terminal sÃ©parÃ©)
tensorboard --logdir logs/tensorboard
```

**C'est tout! L'entraÃ®nement dÃ©marre automatiquement. â±ï¸ Temps: ~2-3 heures**

---

## ğŸ“‹ PrÃ©requis

âœ… Phase 1 complÃ©tÃ©e (voir `PHASE1_INSTRUCTIONS.md`)
âœ… Environnement virtuel `venv_emotion` crÃ©Ã©
âœ… PyTorch avec ROCm installÃ© (ou CPU)
âœ… Compte Kaggle configurÃ© (pour FER2013)

---

## ğŸ”§ Configuration Rapide Kaggle

Si premiÃ¨re fois avec Kaggle:

```bash
# 1. Installer Kaggle API
pip install kaggle

# 2. CrÃ©er ~/.kaggle/kaggle.json
# Aller sur kaggle.com â†’ Account â†’ Create New API Token
# TÃ©lÃ©charger kaggle.json et placer dans ~/.kaggle/

# 3. Set permissions (Linux/WSL)
chmod 600 ~/.kaggle/kaggle.json
```

---

## ğŸ“Š Pendant l'EntraÃ®nement

### Ce qui se passe automatiquement:

âœ… **Epoch 1-100** - Training avec augmentation
âœ… **Early Stopping** - ArrÃªte si pas d'amÃ©lioration (patience=15)
âœ… **Model Checkpoint** - Sauvegarde meilleur modÃ¨le
âœ… **TensorBoard** - Logs en temps rÃ©el
âœ… **LR Scheduling** - Ajuste learning rate
âœ… **Mixed Precision** - FP16 sur GPU AMD

### Fichiers gÃ©nÃ©rÃ©s:

```
checkpoints/
â”œâ”€â”€ best_model_val_loss.pt       â† Meilleur modÃ¨le
â””â”€â”€ checkpoint_epoch*.pt          â† Checkpoints intermÃ©diaires

logs/
â”œâ”€â”€ tensorboard/                  â† Logs TensorBoard
â”‚   â””â”€â”€ 20251025_*/
â”œâ”€â”€ training.log                  â† Log texte
â””â”€â”€ training_history.png          â† Graphique final

models/
â””â”€â”€ emotion_model_scripted.pt     â† ModÃ¨le TorchScript (export)
```

---

## ğŸ“ˆ Monitorer l'EntraÃ®nement

### Option 1: Terminal

Les mÃ©triques s'affichent Ã  chaque epoch:

```
Epoch 10/100 - Time: 85.23s
======================================================================
Train Metrics:
--------------------------------------------------
  loss           : 1.2345
  accuracy       : 0.6234
  f1_macro       : 0.6012
...
```

### Option 2: TensorBoard

```bash
# Dans un terminal sÃ©parÃ©
tensorboard --logdir logs/tensorboard

# Ouvrir navigateur: http://localhost:6006
```

Vous verrez:
- ğŸ“‰ Loss curves (train/val)
- ğŸ“ˆ Accuracy curves
- ğŸ¯ F1-score
- ğŸ”„ Learning rate

---

## âš™ï¸ Personnaliser l'EntraÃ®nement

### Modifier hyperparamÃ¨tres (YAML)

Ã‰ditez `configs/train_config.yaml`:

```yaml
training:
  epochs: 50           # RÃ©duire epochs

optimizer:
  adamw:
    lr: 0.0005         # Changer learning rate

callbacks:
  early_stopping:
    patience: 10       # Patience early stopping
```

### Override via CLI

```bash
# Changer epochs
python scripts/train.py --epochs 50

# Changer batch size
python scripts/train.py --batch-size 128

# Changer learning rate
python scripts/train.py --lr 0.0001

# Combiner plusieurs
python scripts/train.py --epochs 50 --batch-size 128 --lr 0.0001
```

---

## ğŸ”„ Resume Training

Si l'entraÃ®nement s'arrÃªte:

```bash
# Reprendre depuis le dernier checkpoint
python scripts/train.py --resume checkpoints/best_model_val_loss.pt
```

---

## ğŸ¯ MÃ©triques Attendues

### AprÃ¨s ~10 epochs:
- Train Loss: ~1.5
- Val Loss: ~1.6
- Val Accuracy: ~55-60%

### AprÃ¨s ~50 epochs:
- Train Loss: ~0.8
- Val Loss: ~1.0
- Val Accuracy: ~65-70%

### AprÃ¨s ~100 epochs (si pas early stopping):
- Train Loss: ~0.5
- Val Loss: ~0.9
- Val Accuracy: ~70-75%

---

## âš ï¸ ProblÃ¨mes Courants

### GPU non dÃ©tectÃ©

```python
# Dans le code, Ã§a utilise automatiquement CPU si GPU absent
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
```

**Impact**: EntraÃ®nement plus lent (~10x) mais fonctionne.

**Solution permanente**: Voir `PHASE1_INSTRUCTIONS.md` pour setup GPU.

### Out of Memory (CUDA OOM)

RÃ©duire batch size dans `configs/data_config.yaml`:

```yaml
dataloader:
  batch_size: 32  # Au lieu de 64
```

Ou en CLI:
```bash
python scripts/train.py --batch-size 32
```

### Download Ã©choue (Kaggle)

VÃ©rifier:
1. Kaggle API installÃ©e: `pip list | grep kaggle`
2. Credentials configurÃ©es: `ls -la ~/.kaggle/kaggle.json`
3. Permissions OK: `chmod 600 ~/.kaggle/kaggle.json`

**Alternative**: TÃ©lÃ©charger manuellement depuis [Kaggle](https://www.kaggle.com/datasets/msambare/fer2013)

### num_workers error (WSL2)

Si erreur avec DataLoader workers:

```yaml
# configs/data_config.yaml
dataloader:
  num_workers: 0  # DÃ©sactiver multi-processing
```

---

## ğŸ“Š RÃ©sultats Attendus

### Fichiers gÃ©nÃ©rÃ©s aprÃ¨s entraÃ®nement complet:

```
checkpoints/best_model_val_loss.pt       2.5 MB
logs/training_history.png                 120 KB
logs/tensorboard/20251025_*/events.*      5 MB
models/emotion_model_scripted.pt          2.8 MB
```

### MÃ©triques finales (typiques):

```
Best validation loss: 0.8542
Best validation accuracy: 0.7123
Best validation F1: 0.6987

Per-class Accuracy:
  angry    : 0.6234
  disgust  : 0.5123  â† Difficile (peu d'exemples)
  fear     : 0.6789
  happy    : 0.8456  â† Plus facile
  sad      : 0.7012
  surprise : 0.7345
  neutral  : 0.7234
```

---

## ğŸ“ AprÃ¨s l'EntraÃ®nement

### 1. Analyser les rÃ©sultats

```bash
# Voir graphiques
open logs/training_history.png

# TensorBoard
tensorboard --logdir logs/tensorboard
```

### 2. Tester le modÃ¨le

```python
# Dans Python ou Jupyter
import torch
from src.models.emotion_net import EmotionNetNano

# Charger modÃ¨le
model = EmotionNetNano(num_classes=7)
checkpoint = torch.load('checkpoints/best_model_val_loss.pt')
model.load_state_dict(checkpoint['model_state_dict'])
model.eval()

# Tester sur une image
# ... (voir notebooks pour exemples complets)
```

### 3. Fine-tuning sur RAF-DB (optionnel)

```bash
# 1. TÃ©lÃ©charger RAF-DB (manuel)
# 2. PrÃ©parer
python scripts/prepare_data.py --dataset data/rafdb --all

# 3. Fine-tuner
# Modifier configs/train_config.yaml:
#   fine_tuning.enabled = true
#   fine_tuning.checkpoint_path = "checkpoints/best_model_val_loss.pt"

python scripts/train.py --config configs/train_config.yaml
```

---

## ğŸ’¡ Tips & Tricks

### AccÃ©lÃ©rer l'entraÃ®nement

1. **Augmenter batch size** (si VRAM suffisante)
   ```bash
   python scripts/train.py --batch-size 128
   ```

2. **Utiliser mixed precision** (dÃ©jÃ  activÃ© par dÃ©faut)
   ```yaml
   training:
     use_mixed_precision: true  # FP16
   ```

3. **Augmenter num_workers**
   ```yaml
   dataloader:
     num_workers: 8  # Si CPU puissant
   ```

### AmÃ©liorer accuracy

1. **Plus d'epochs**
   ```bash
   python scripts/train.py --epochs 150
   ```

2. **Learning rate plus petit**
   ```bash
   python scripts/train.py --lr 0.0005
   ```

3. **Augmentation plus forte**
   Modifier `configs/data_config.yaml` â†’ augmentation

4. **Essayer autre modÃ¨le**
   ```yaml
   # configs/train_config.yaml
   model:
     name: "resnet18"  # Au lieu de emotionnet_nano
     pretrained: true
   ```

---

## ğŸš€ En RÃ©sumÃ©

```bash
# Installation une fois
./setup/phase1_setup.sh

# Ã€ chaque entraÃ®nement
source venv_emotion/bin/activate
python scripts/download_datasets.py --dataset fer2013  # Une fois
python scripts/prepare_data.py --dataset data/fer2013 --all  # Une fois
python scripts/train.py  # EntraÃ®nement
```

**C'est tout! Le systÃ¨me fait le reste automatiquement. ğŸ‰**

---

**Temps total**:
- Setup: ~1h (une fois)
- Download: ~10 min
- Prepare: ~5 min
- Training: ~2-3h (AMD 7900 XT) ou ~24h (CPU)

**PrÃªt? `python scripts/train.py` et c'est parti! ğŸš€**
