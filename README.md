# ğŸ“ SystÃ¨me d'Identification d'Ã‰tudiants avec Analyse d'Ã‰motions

SystÃ¨me de reconnaissance faciale en temps rÃ©el combinant l'identification d'Ã©tudiants et l'analyse de leurs Ã©tats Ã©motionnels, optimisÃ© pour AMD Radeon 7900 XT.

## ğŸ“‹ Table des MatiÃ¨res

- [CaractÃ©ristiques](#caractÃ©ristiques)
- [PrÃ©requis](#prÃ©requis)
- [Installation](#installation)
- [Utilisation](#utilisation)
- [Architecture](#architecture)
- [Documentation](#documentation)
- [Licence](#licence)

## âœ¨ CaractÃ©ristiques

- âœ… Reconnaissance faciale en temps rÃ©el (>25 FPS)
- âœ… DÃ©tection de 7 Ã©motions de base
- âœ… Identification d'Ã©tudiants
- âœ… OptimisÃ© pour AMD Radeon 7900 XT avec ROCm
- âœ… Interface de visualisation en direct
- âœ… Logging et statistiques

## ğŸ”§ PrÃ©requis

### MatÃ©riel
- **GPU** : AMD Radeon RX 7900 XT (20 GB VRAM)
- **RAM** : 16 GB minimum, 64 GB recommandÃ©
- **Stockage** : 50 GB disponibles (pour datasets et modÃ¨les)

### Logiciel
- **OS** : Ubuntu 22.04 LTS (recommandÃ©) ou Windows 11
- **Python** : 3.10+
- **ROCm** : 5.7 ou supÃ©rieur
- **Webcam** : CamÃ©ra compatible (rÃ©solution 720p minimum)

## ğŸ“¦ Installation

### 1. Installer ROCm (Ubuntu)

```bash
# Ajouter les dÃ©pÃ´ts AMD
wget https://repo.radeon.com/amdgpu-install/latest/ubuntu/jammy/amdgpu-install_5.7.50700-1_all.deb
sudo dpkg -i amdgpu-install_5.7.50700-1_all.deb
sudo apt update

# Installer ROCm
sudo amdgpu-install --usecase=rocm

# Ajouter utilisateur au groupe render
sudo usermod -a -G render,video $LOGNAME

# RedÃ©marrer
sudo reboot
```

### 2. VÃ©rifier l'installation ROCm

```bash
rocm-smi
rocminfo | grep "Name:"
```

Vous devriez voir votre AMD Radeon RX 7900 XT.

### 3. CrÃ©er l'environnement Python

```bash
# Cloner le projet
cd ~/Downloads
cd "Projet IA identification Ã©tudiant"

# CrÃ©er environnement virtuel
python3.10 -m venv venv_emotion
source venv_emotion/bin/activate  # Linux
# ou
venv_emotion\Scripts\activate  # Windows

# Mettre Ã  jour pip
pip install --upgrade pip
```

### 4. Installer PyTorch avec ROCm

```bash
pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm5.7
```

### 5. Installer les dÃ©pendances

```bash
pip install -r requirements.txt
```

### 6. Tester l'installation GPU

```bash
python scripts/test_gpu.py
```

Sortie attendue :
```
PyTorch version: 2.x.x
CUDA available: True
Device count: 1
Device name: AMD Radeon RX 7900 XT
Device memory: 20.00 GB
âœ… GPU dÃ©tectÃ© et fonctionnel !
```

## ğŸš€ Utilisation

### DÃ©marrage Rapide

```bash
# Activer l'environnement
source venv_emotion/bin/activate

# Lancer le systÃ¨me en temps rÃ©el
python main.py --mode realtime

# Ou avec configuration personnalisÃ©e
python main.py --config configs/config.yaml
```

### Modes d'Utilisation

#### 1. Mode Temps RÃ©el (Webcam)
```bash
python main.py --mode realtime
```

#### 2. Mode Traitement VidÃ©o
```bash
python main.py --mode video --input path/to/video.mp4
```

#### 3. Mode Image Unique
```bash
python main.py --mode image --input path/to/image.jpg
```

#### 4. Mode EntraÃ®nement
```bash
python scripts/train.py --config configs/train_config.yaml
```

### Options de Ligne de Commande

```bash
python main.py --help

Options:
  --mode {realtime,video,image}  Mode d'exÃ©cution
  --config PATH                  Fichier de configuration
  --model PATH                   Chemin vers le modÃ¨le
  --device {cuda,cpu}            Device Ã  utiliser
  --fps-target INT               FPS cible (dÃ©faut: 30)
  --show-fps                     Afficher FPS en temps rÃ©el
  --save-output PATH             Sauvegarder la sortie
```

## ğŸ—ï¸ Architecture du Projet

```
Projet IA identification Ã©tudiant/
â”œâ”€â”€ README.md                  # Ce fichier
â”œâ”€â”€ projet.md                  # Documentation dÃ©taillÃ©e du projet
â”œâ”€â”€ plan.md                    # Roadmap de dÃ©veloppement
â”œâ”€â”€ requirements.txt           # DÃ©pendances Python
â”œâ”€â”€ main.py                    # Point d'entrÃ©e principal
â”œâ”€â”€ setup.py                   # Installation du package
â”‚
â”œâ”€â”€ configs/                   # Fichiers de configuration
â”‚   â”œâ”€â”€ config.yaml           # Configuration principale
â”‚   â”œâ”€â”€ train_config.yaml     # Configuration entraÃ®nement
â”‚   â””â”€â”€ model_config.yaml     # Configuration modÃ¨le
â”‚
â”œâ”€â”€ src/                       # Code source
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ models/               # Architectures de modÃ¨les
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ emotion_net.py    # EmotionNet Nano
â”‚   â”‚   â”œâ”€â”€ efficient_net.py  # EfficientNet wrapper
â”‚   â”‚   â””â”€â”€ face_embedding.py # ModÃ¨les d'embedding
â”‚   â”‚
â”‚   â”œâ”€â”€ data/                 # Gestion des donnÃ©es
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ datasets.py       # PyTorch Datasets
â”‚   â”‚   â”œâ”€â”€ transforms.py     # Augmentations
â”‚   â”‚   â””â”€â”€ loaders.py        # DataLoaders
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/                # Utilitaires
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ face_detector.py  # MTCNN/Haar Cascade
â”‚   â”‚   â”œâ”€â”€ preprocessor.py   # PrÃ©traitement
â”‚   â”‚   â”œâ”€â”€ visualizer.py     # Visualisation
â”‚   â”‚   â””â”€â”€ logger.py         # Logging
â”‚   â”‚
â”‚   â”œâ”€â”€ core/                 # Logique mÃ©tier
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ emotion_classifier.py
â”‚   â”‚   â”œâ”€â”€ student_identifier.py
â”‚   â”‚   â””â”€â”€ system.py         # SystÃ¨me intÃ©grÃ©
â”‚   â”‚
â”‚   â””â”€â”€ train/                # Scripts d'entraÃ®nement
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ trainer.py
â”‚       â””â”€â”€ evaluator.py
â”‚
â”œâ”€â”€ scripts/                   # Scripts utilitaires
â”‚   â”œâ”€â”€ test_gpu.py           # Test GPU
â”‚   â”œâ”€â”€ download_datasets.py  # TÃ©lÃ©chargement datasets
â”‚   â”œâ”€â”€ train.py              # EntraÃ®nement
â”‚   â”œâ”€â”€ evaluate.py           # Ã‰valuation
â”‚   â””â”€â”€ benchmark.py          # Benchmarking
â”‚
â”œâ”€â”€ notebooks/                 # Jupyter notebooks
â”‚   â”œâ”€â”€ 01_EDA.ipynb          # Analyse exploratoire
â”‚   â”œâ”€â”€ 02_Training.ipynb     # EntraÃ®nement
â”‚   â””â”€â”€ 03_Evaluation.ipynb   # Ã‰valuation
â”‚
â”œâ”€â”€ data/                      # DonnÃ©es (non versionnÃ©)
â”‚   â”œâ”€â”€ fer2013/
â”‚   â”œâ”€â”€ rafdb/
â”‚   â””â”€â”€ students/
â”‚
â”œâ”€â”€ models/                    # ModÃ¨les entraÃ®nÃ©s (non versionnÃ©)
â”‚   â”œâ”€â”€ emotion_net_nano.pt
â”‚   â”œâ”€â”€ emotion_net_scripted.pt
â”‚   â””â”€â”€ student_embeddings.pkl
â”‚
â””â”€â”€ logs/                      # Logs et rÃ©sultats (non versionnÃ©)
    â”œâ”€â”€ tensorboard/
    â”œâ”€â”€ checkpoints/
    â””â”€â”€ results/
```

## ğŸ“Š Datasets

### TÃ©lÃ©chargement Automatique

```bash
python scripts/download_datasets.py --dataset fer2013
python scripts/download_datasets.py --dataset rafdb
```

### Datasets SupportÃ©s

1. **FER2013** : ~35,000 images, 7 Ã©motions
2. **RAF-DB** : ~30,000 images haute qualitÃ©
3. **CK+** : ~593 sÃ©quences vidÃ©o (conditions lab)

Voir `projet.md` pour plus de dÃ©tails sur les datasets.

## ğŸ¯ Performance

### MÃ©triques Cibles

| MÃ©trique | Cible | Ã‰tat |
|----------|-------|------|
| FPS | >30 | â³ |
| Latence | <33ms | â³ |
| PrÃ©cision Ã‰motions | >70% | â³ |
| PrÃ©cision Identification | >95% | â³ |

### Benchmarking

```bash
python scripts/benchmark.py --iterations 1000
```

## ğŸ”¬ DÃ©veloppement

### Tests

```bash
# Installer dÃ©pendances de test
pip install pytest pytest-cov

# Lancer les tests
pytest tests/

# Avec couverture
pytest --cov=src tests/
```

### EntraÃ®ner un Nouveau ModÃ¨le

```bash
python scripts/train.py \
    --model emotion_net_nano \
    --dataset fer2013 \
    --epochs 50 \
    --batch-size 64 \
    --lr 0.001
```

### Ã‰valuation

```bash
python scripts/evaluate.py \
    --model models/emotion_net_nano.pt \
    --dataset data/fer2013/test
```

## ğŸ“ Documentation

- **`projet.md`** : Documentation technique complÃ¨te
- **`plan.md`** : Roadmap de dÃ©veloppement en 6 phases
- **Notebooks** : Tutoriels interactifs dans `notebooks/`

## ğŸ¤ Contribution

Ce projet est dÃ©veloppÃ© dans un cadre acadÃ©mique. Pour toute suggestion :

1. CrÃ©er une issue
2. Proposer une pull request
3. Contacter l'Ã©quipe

## âš–ï¸ ConsidÃ©rations Ã‰thiques

âš ï¸ **Important** : Ce systÃ¨me traite des donnÃ©es biomÃ©triques sensibles.

- Obtenir le consentement explicite avant collecte
- Respecter le RGPD et lÃ©gislations locales
- Chiffrer les donnÃ©es stockÃ©es
- Limiter la rÃ©tention des donnÃ©es
- Auditer les biais algorithmiques

Voir `projet.md` section "ConsidÃ©rations Ã‰thiques" pour plus de dÃ©tails.

## ğŸ“„ Licence

[Ã€ dÃ©finir selon le contexte acadÃ©mique/commercial]

## ğŸ™ Remerciements

- AMD pour le support ROCm sur Radeon 7900 XT
- Ã‰quipe PyTorch pour l'intÃ©gration ROCm
- CommunautÃ© DeepFace
- CrÃ©ateurs des datasets FER2013, RAF-DB, CK+

## ğŸ“ Support

Pour toute question :
- Consulter `projet.md` et `plan.md`
- Ouvrir une issue GitHub
- Contacter l'Ã©quipe du projet

---

**Version** : 1.0
**DerniÃ¨re mise Ã  jour** : 2025-10-25
**OptimisÃ© pour** : AMD Radeon RX 7900 XT avec ROCm 5.7+
