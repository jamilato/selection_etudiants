# üîß Guide d'Installation ROCm pour AMD Radeon 7900 XT

Guide complet pour installer et configurer ROCm + PyTorch sur AMD Radeon RX 7900 XT pour le deep learning.

## üìã Table des Mati√®res

- [Pr√©requis](#pr√©requis)
- [Installation Ubuntu](#installation-ubuntu)
- [Installation Windows](#installation-windows)
- [V√©rification](#v√©rification)
- [D√©pannage](#d√©pannage)
- [Optimisations](#optimisations)

---

## üîç Pr√©requis

### Mat√©riel Requis
- **GPU** : AMD Radeon RX 7900 XT (RDNA 3, 20 GB VRAM)
- **RAM** : 16 GB minimum, 64 GB recommand√©
- **Stockage** : 50 GB d'espace libre

### Syst√®mes d'Exploitation Support√©s
- ‚úÖ **Ubuntu 22.04 LTS** (RECOMMAND√â - support stable)
- ‚úÖ **Ubuntu 20.04 LTS** (support√©)
- ‚ö†Ô∏è **Windows 11** (support preview, moins stable)
- ‚ùå **Windows 10** (non support√© officiellement)

---

## üêß Installation Ubuntu (RECOMMAND√â)

### √âtape 1 : Pr√©paration du Syst√®me

```bash
# Mettre √† jour le syst√®me
sudo apt update && sudo apt upgrade -y

# Installer d√©pendances de base
sudo apt install -y \
    build-essential \
    git \
    wget \
    curl \
    python3.10 \
    python3.10-venv \
    python3-pip \
    libgl1-mesa-glx \
    libglib2.0-0
```

### √âtape 2 : Installation du Driver AMD et ROCm

#### Option A : Installation Automatique (Recommand√©)

```bash
# T√©l√©charger l'installeur AMD
wget https://repo.radeon.com/amdgpu-install/latest/ubuntu/jammy/amdgpu-install_5.7.50700-1_all.deb

# Installer le package
sudo dpkg -i amdgpu-install_5.7.50700-1_all.deb

# Mettre √† jour les d√©p√¥ts
sudo apt update

# Installer ROCm complet
sudo amdgpu-install --usecase=rocm -y
```

#### Option B : Installation Manuelle

```bash
# Ajouter les cl√©s GPG
wget -qO - https://repo.radeon.com/rocm/rocm.gpg.key | sudo apt-key add -

# Ajouter le d√©p√¥t ROCm
echo 'deb [arch=amd64] https://repo.radeon.com/rocm/apt/5.7 ubuntu main' | \
    sudo tee /etc/apt/sources.list.d/rocm.list

# Installer ROCm
sudo apt update
sudo apt install rocm-hip-sdk rocm-libs -y
```

### √âtape 3 : Configuration des Permissions

```bash
# Ajouter l'utilisateur aux groupes render et video
sudo usermod -a -G render,video $LOGNAME

# V√©rifier l'appartenance aux groupes
groups $LOGNAME
```

**‚ö†Ô∏è IMPORTANT** : D√©connectez-vous et reconnectez-vous (ou red√©marrez) pour que les changements de groupe prennent effet.

```bash
sudo reboot
```

### √âtape 4 : V√©rification de l'Installation ROCm

Apr√®s red√©marrage :

```bash
# V√©rifier ROCm
rocm-smi

# V√©rifier les informations GPU
rocminfo | grep -A 5 "Name:"

# V√©rifier la version ROCm
/opt/rocm/bin/rocm-smi --showdriverversion
```

**Sortie attendue pour rocm-smi :**
```
========================= ROCm System Management Interface =========================
=========================== GPU0 : AMD Radeon RX 7900 XT ===========================
GPU[0]  : Temperature: 45.0¬∞C
GPU[0]  : GPU use (%): 0
GPU[0]  : Memory use: 0% (0MB / 20480MB)
```

### √âtape 5 : Installation de Python et Environnement Virtuel

```bash
# V√©rifier version Python
python3.10 --version

# Cr√©er environnement virtuel
cd ~/path/to/project
python3.10 -m venv venv_emotion

# Activer l'environnement
source venv_emotion/bin/activate

# Mettre √† jour pip
pip install --upgrade pip
```

### √âtape 6 : Installation de PyTorch avec Support ROCm

```bash
# Installer PyTorch avec ROCm 5.7
pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm5.7
```

**Versions sp√©cifiques** (optionnel, si vous avez besoin d'une version pr√©cise) :
```bash
# PyTorch 2.1.0 avec ROCm 5.7 (exemple)
pip3 install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 \
    --index-url https://download.pytorch.org/whl/rocm5.7
```

### √âtape 7 : V√©rification de PyTorch

Cr√©er un script de test `test_pytorch_rocm.py` :

```python
import torch

print("=" * 60)
print("Test PyTorch + ROCm")
print("=" * 60)

# Version PyTorch
print(f"\nPyTorch version: {torch.__version__}")

# V√©rifier CUDA (ROCm appara√Æt comme CUDA)
print(f"CUDA available: {torch.cuda.is_available()}")

if torch.cuda.is_available():
    print(f"CUDA device count: {torch.cuda.device_count()}")
    print(f"CUDA device name: {torch.cuda.get_device_name(0)}")
    print(f"CUDA device memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB")

    # Test calcul GPU
    x = torch.randn(1000, 1000).cuda()
    y = torch.randn(1000, 1000).cuda()
    z = torch.matmul(x, y)
    print("\n‚úÖ Test de calcul GPU r√©ussi!")
else:
    print("\n‚ùå GPU non d√©tect√©!")
```

Ex√©cuter :
```bash
python test_pytorch_rocm.py
```

**Sortie attendue :**
```
============================================================
Test PyTorch + ROCm
============================================================

PyTorch version: 2.x.x+rocm5.7
CUDA available: True
CUDA device count: 1
CUDA device name: AMD Radeon RX 7900 XT
CUDA device memory: 20.00 GB

‚úÖ Test de calcul GPU r√©ussi!
```

### √âtape 8 : Installation des D√©pendances du Projet

```bash
# Dans le r√©pertoire du projet
cd ~/path/to/projet

# Activer environnement si n√©cessaire
source venv_emotion/bin/activate

# Installer d√©pendances
pip install -r requirements.txt
```

---

## ü™ü Installation Windows (Preview)

### Pr√©requis Windows

- Windows 11 (version 22H2 ou plus r√©cente)
- AMD Radeon RX 7900 XT avec drivers r√©cents
- Python 3.10 ou 3.11

### √âtape 1 : Installer le Driver AMD

1. T√©l√©charger **AMD Software: Adrenalin Edition** depuis [AMD.com](https://www.amd.com/en/support)
2. Installer le driver complet
3. Red√©marrer

### √âtape 2 : Installer PyTorch avec DirectML (Alternative ROCm)

ROCm sur Windows est en preview. Alternative recommand√©e : **DirectML**

```powershell
# Cr√©er environnement virtuel
python -m venv venv_emotion
venv_emotion\Scripts\activate

# Installer PyTorch avec DirectML
pip install torch-directml
pip install torchvision torchaudio
```

### √âtape 3 : Test DirectML

```python
import torch
import torch_directml

dml = torch_directml.device()
print(f"DirectML device: {dml}")

x = torch.randn(1000, 1000).to(dml)
y = torch.randn(1000, 1000).to(dml)
z = torch.matmul(x, y)
print("‚úÖ DirectML fonctionnel!")
```

### PyTorch ROCm sur Windows (Experimental)

‚ö†Ô∏è **Attention** : Support experimental, bugs possibles

```powershell
# Installer ROCm pour Windows (preview)
# T√©l√©charger depuis: https://github.com/RadeonOpenCompute/ROCm/releases

# Installer PyTorch preview
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm5.7
```

---

## ‚úÖ V√©rification Compl√®te

### Script de V√©rification Complet

Utiliser le script fourni dans le projet :

```bash
python scripts/test_gpu.py
```

Ce script v√©rifie :
- ‚úÖ Version PyTorch
- ‚úÖ D√©tection GPU
- ‚úÖ M√©moire VRAM
- ‚úÖ Calculs matriciels
- ‚úÖ Mixed Precision (FP16)

### Benchmarking Performance

```bash
# Tester performance du GPU
python -c "
import torch
import time

device = torch.device('cuda')
size = 8192

a = torch.randn(size, size).to(device)
b = torch.randn(size, size).to(device)

torch.cuda.synchronize()
start = time.time()

c = torch.matmul(a, b)
torch.cuda.synchronize()

elapsed = time.time() - start
tflops = (2 * size**3) / (elapsed * 1e12)

print(f'Temps: {elapsed:.4f}s')
print(f'Performance: {tflops:.2f} TFLOPS')
"
```

**Performance attendue AMD 7900 XT** : 30-50 TFLOPS (FP32)

---

## üîß D√©pannage

### Probl√®me : GPU non d√©tect√© par PyTorch

**Causes possibles :**
1. ROCm mal install√©
2. Utilisateur pas dans les groupes `render` et `video`
3. Version incompatible PyTorch/ROCm

**Solutions :**

```bash
# 1. V√©rifier ROCm
rocm-smi

# 2. V√©rifier groupes
groups $LOGNAME
# Si render/video absents:
sudo usermod -a -G render,video $LOGNAME
# Puis se d√©connecter/reconnecter

# 3. R√©installer PyTorch
pip uninstall torch torchvision torchaudio
pip cache purge
pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm5.7

# 4. V√©rifier variables d'environnement
export HSA_OVERRIDE_GFX_VERSION=11.0.0  # Pour RDNA 3
python test_pytorch_rocm.py
```

### Probl√®me : Erreur "HIP out of memory"

**Solution :**
```python
# R√©duire batch size
batch_size = 32  # au lieu de 64

# Activer gradient checkpointing
torch.utils.checkpoint.checkpoint(...)

# Lib√©rer cache
torch.cuda.empty_cache()
```

### Probl√®me : Performance Lente

**Optimisations :**

```python
# 1. Activer TF32 (si support√©)
torch.backends.cudnn.allow_tf32 = True

# 2. Activer benchmark
torch.backends.cudnn.benchmark = True

# 3. Utiliser Mixed Precision
from torch.cuda.amp import autocast, GradScaler

scaler = GradScaler()
with autocast():
    output = model(input)
```

### Probl√®me : Driver Conflicts

Si vous avez des probl√®mes apr√®s mise √† jour driver :

```bash
# Purger anciens packages
sudo apt purge rocm-* amdgpu-*
sudo apt autoremove
sudo apt clean

# R√©installer proprement
sudo amdgpu-install --usecase=rocm -y
sudo reboot
```

---

## ‚ö° Optimisations Avanc√©es

### 1. Variables d'Environnement ROCm

Ajouter √† `~/.bashrc` :

```bash
# ROCm paths
export ROCM_PATH=/opt/rocm
export PATH=$ROCM_PATH/bin:$PATH
export LD_LIBRARY_PATH=$ROCM_PATH/lib:$LD_LIBRARY_PATH

# Pour RDNA 3 (7900 XT)
export HSA_OVERRIDE_GFX_VERSION=11.0.0

# Optimisations
export HSA_ENABLE_SDMA=0
export GPU_MAX_HW_QUEUES=4
```

Recharger :
```bash
source ~/.bashrc
```

### 2. Tuning GPU avec rocm-smi

```bash
# Augmenter limite de puissance (si refroidissement ad√©quat)
sudo rocm-smi --setpoweroverdrive 10  # +10%

# D√©finir profil performance
sudo rocm-smi --setperflevel high

# Monitorer
watch -n 1 rocm-smi
```

### 3. Configuration PyTorch Optimale

```python
import torch

# Configuration pour AMD 7900 XT
torch.backends.cudnn.benchmark = True
torch.backends.cudnn.deterministic = False
torch.backends.cudnn.allow_tf32 = True

# Mixed Precision
torch.set_float32_matmul_precision('high')

# Batch size optimal (√† ajuster)
batch_size = 64  # Maximiser utilisation 20 GB VRAM
```

### 4. Monitoring en Temps R√©el

```bash
# Terminal 1 : Monitoring GPU
watch -n 0.5 rocm-smi

# Terminal 2 : Monitoring syst√®me
htop

# Alternative : radeontop
sudo apt install radeontop
sudo radeontop
```

---

## üìö Ressources Utiles

### Documentation Officielle
- [ROCm Documentation](https://rocm.docs.amd.com/)
- [PyTorch ROCm](https://pytorch.org/get-started/locally/)
- [AMD GPUs for AI](https://www.amd.com/en/graphics/servers-radeon-instinct-mi)

### Communaut√©
- [ROCm GitHub](https://github.com/RadeonOpenCompute/ROCm)
- [PyTorch Forums - AMD](https://discuss.pytorch.org/)
- [r/ROCM](https://www.reddit.com/r/ROCm/)

### Tutoriels
- [Getting Started with ROCm](https://github.com/RadeonOpenCompute/ROCm)
- [PyTorch AMD Tutorial](https://pytorch.org/blog/amd-extends-support-for-pt-ml/)

---

## üéØ Checklist Finale

Avant de commencer le projet, v√©rifiez :

- [ ] ROCm install√© (`rocm-smi` fonctionne)
- [ ] GPU d√©tect√© (`rocminfo` montre 7900 XT)
- [ ] Utilisateur dans groupes render/video
- [ ] PyTorch install√© avec ROCm
- [ ] GPU d√©tect√© par PyTorch (`torch.cuda.is_available() == True`)
- [ ] Test de calcul GPU r√©ussi
- [ ] Mixed Precision fonctionne
- [ ] D√©pendances du projet install√©es
- [ ] Script `test_gpu.py` passe tous les tests

Si tous les points sont ‚úÖ, vous √™tes pr√™t !

---

**Derni√®re mise √† jour** : 2025-10-25
**Version ROCm** : 5.7+
**GPU test√©** : AMD Radeon RX 7900 XT
